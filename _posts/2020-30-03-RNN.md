---
layout: post
title: Recurrent Neural Network (RNN) 
date:   2020-03-30 21:00:00
categories: RNN
---
<h1 style="text-align: justify;"><span style="color: #3366ff; background-color: #ffcc99;"><strong>2 - Recurrent Neural Network (RNN)</strong></span></h1>  

# NỘI DUNG
1. [Ý tưởng đằng sau RNN](#1)
2. [Ứng dụng của RNN](#2)
3. [Vấn đề Vanishing Gradient ](#3)  
4. [Long Short-Term Memory (LSTM)](#4)
5. [Các biến thể của LSTM](#5)


## 1.Ý tưởng đằng sau RNN <a name="1"></a>  
__1.1. Neural network và não bộ con người__
 Như chúng ta đã biết thì các lý thuyết cơ sở của Deep Learning được hình và phát triển dựa trên sự bắt chước theo mô hình của não bộ con người.<br>
 Não người gồm có 3 phần bao gồm: đại não ([cerebrum](https://en.wikipedia.org/wiki/Cerebrum)), là hình ảnh phía dưới, tiểu não ([cerebellum](https://en.wikipedia.org/wiki/Cerebellum)) và trụ não ([brainstem](https://en.wikipedia.org/wiki/Brainstem)), được liên kết với tủy.
 ![](https://upload.wikimedia.org/wikipedia/vi/e/e1/Nao_nguoi.jpg)
 _Nguồn: [Wiki](https://vi.wikipedia.org/wiki/N%C3%A3o_ng%C6%B0%E1%BB%9Di)_<br>
__1.2. Liên hệ giữa thùy trán và RNN__<br>
   RNNs hoạt động giống như trí nhớ tạm thời vậy, chúng ta sẽ học được những hiện tượng qua một vài lần bắt gặp mà sử dụng nó vào những việc sau này.<br>
   Đối với con người, trí nhớ ngắn hạn là một trong những chức năng của thùy trán.
 <br>
__1.3. Biểu diễn mô hình RNN__
  Ta bắt đầu chuyển đổi một mô hình ANN sang RNN <br>
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/1.png)
  1. Nén lại. Các lớp vẫn nguyên, ta hãy tưởng tượng đang quan sát mô hình từ phía dưới
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/2.png)
  2. Giản lượt bớt các mũi tên
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/3.png)
  3. Xoay theo chiều thẳng đứng theo đúng mô hình chuẩn
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/4.png)
  4. Thêm vào vòng lặp (temporal loop), hidden layer không chỉ đưa ra output mà còn phản hồi lại chính nó (đây là cách biểu diễn cũ).
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/5.png)
  5. Bỏ kiếm soát vòng lặp và biểu diễn RNN theo cách mới. Bây giờ, mỗi vòng tròn không chỉ là một neuron mà còn là một lớp neuron
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/6.png)
 
 
## 2.  Ứng dụng của RNN <a name="2"></a><br>
  __One to Many__ : RNN có một input và nhiều output
  ![](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/41_blog_image_11.png)
  Bức ảnh này ban đầu đi qua CNN để xử lý ảnh (image processing) và nhận dạng đặc trưng (feature  recognition), rồi qua RNN để máy tính cho ra một câu có nghĩa :"black and white dog jumps over bar".<br>
   Có thể ứng dụng vào các __search engine__, __eCommerce__,__social media__ như Facebook, Instagram.<br>
  __Many to One__: RNN có nhiều input và một output
  ![](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/41_blog_image_12.png)
  Một ví dụ rất quen thuộc là bài toán phân tích cảm xúc (sentiment analysis), khi một câu có nhiều từ như lời bình luận khách hàng, phản hồi của sinh viên,... ta cần một thứ có thể đánh giá được câu đó mang ý nghĩa tích cực, tiêu cực hay trung tính bao nhiêu, qua đó để có chiến lược quảng bá, sửa đổi thích hợp.<br>
   __Many to Many__: RNN có nhiều input lẫn output
   ![](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/41_blog_image_13.png)
   Ví dụ trong trường hợp này là công cụ dịch ngôn ngữ như Google Translaltor.
    ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/gg.png)
   Có ứng dụng vào dịch máy (machine translation),text summarization,chatbots...<br>
    

