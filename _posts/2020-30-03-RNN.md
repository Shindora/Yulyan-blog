---
layout: post
title: Recurrent Neural Network (RNN) 
date:   2020-03-30 21:00:00
categories: RNN
---
<h1 style="text-align: justify;"><span style="color: #3366ff; background-color: #ffcc99;"><strong>2 - Recurrent Neural Network (RNN)</strong></span></h1>  

# NỘI DUNG
1. [Ý tưởng đằng sau RNN](#1)
2. [Ứng dụng của RNN](#2)
3. [Vấn đề Vanishing Gradient ](#3)  
4. [Long Short-Term Memory (LSTM)](#4)
5. [Các biến thể của LSTM](#5)


## 1.Ý tưởng đằng sau RNN <a name="1"></a>  
__1.1. Neural network và não bộ con người__
 Như chúng ta đã biết thì các lý thuyết cơ sở của Deep Learning được hình và phát triển dựa trên sự bắt chước theo mô hình của não bộ con người.<br>
 Não người gồm có 3 phần bao gồm: đại não ([cerebrum](https://en.wikipedia.org/wiki/Cerebrum)), là hình ảnh phía dưới, tiểu não ([cerebellum](https://en.wikipedia.org/wiki/Cerebellum)) và trụ não ([brainstem](https://en.wikipedia.org/wiki/Brainstem)), được liên kết với tủy.
 ![](https://upload.wikimedia.org/wikipedia/vi/e/e1/Nao_nguoi.jpg)
 _Nguồn: [Wiki](https://vi.wikipedia.org/wiki/N%C3%A3o_ng%C6%B0%E1%BB%9Di)_<br>
__1.2. Liên hệ giữa thùy trán và RNN__<br>
   RNNs hoạt động giống như trí nhớ tạm thời vậy, chúng ta sẽ học được những hiện tượng qua một vài lần bắt gặp mà sử dụng nó vào những việc sau này.<br>
   Đối với con người, trí nhớ ngắn hạn là một trong những chức năng của thùy trán.
 <br>
__1.3. Biểu diễn mô hình RNN__
  Ta bắt đầu chuyển đổi một mô hình ANN sang RNN <br>
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/1.png)
  1. Nén lại. Các lớp vẫn nguyên, ta hãy tưởng tượng đang quan sát mô hình từ phía dưới
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/2.png)
  2. Giản lượt bớt các mũi tên
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/3.png)
  3. Xoay theo chiều thẳng đứng theo đúng mô hình chuẩn
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/4.png)
  4. Thêm vào vòng lặp (temporal loop), hidden layer không chỉ đưa ra output mà còn phản hồi lại chính nó (đây là cách biểu diễn cũ).
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/5.png)
  5. Bỏ kiếm soát vòng lặp và biểu diễn RNN theo cách mới. Bây giờ, mỗi vòng tròn không chỉ là một neuron mà còn là một lớp neuron
  ![](https://raw.githubusercontent.com/Shindora/Yulyan-blog/gh-pages/assets/rnn/6.png)
 
  
